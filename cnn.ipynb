{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pnd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import os\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#load data\n",
    "dataset = 1\n",
    "match dataset:\n",
    "    case 1:\n",
    "        test = 'fashion-mnist_test.csv'\n",
    "        train = 'fashion-mnist_train.csv'\n",
    "    case 2: \n",
    "        test = \"mnist_test.csv\"\n",
    "        train = \"mnist_train.csv\"\n",
    "testdata = pnd.read_csv(test)\n",
    "traindata = pnd.read_csv(train)\n",
    "\n",
    "#split into images and labels\n",
    "testdata_pixel = testdata.drop(testdata.columns[0], axis=1).to_numpy()\n",
    "traindata_pixel = traindata.drop(traindata.columns[0], axis=1).to_numpy()\n",
    "label_train = traindata[traindata.columns[0]].to_numpy()\n",
    "label_test = testdata[testdata.columns[0]].to_numpy()\n",
    "og_label_train = label_train.copy()\n",
    "og_label_test = label_test.copy()\n",
    "\n",
    "#reshape for cnn\n",
    "cnn_test = testdata_pixel.reshape(-1,28,28) /255.0\n",
    "cnn_train = traindata_pixel.reshape(-1,28,28) /255.0\n",
    "cnn_test = np.expand_dims(cnn_test,axis=3)\n",
    "cnn_train = np.expand_dims(cnn_train,axis=3)\n",
    "cnn_label_test = tf.keras.utils.to_categorical(label_test)\n",
    "cnn_label_train = tf.keras.utils.to_categorical(label_train)\n",
    "\n",
    "softmax_nodes = 10\n",
    "class_names = np.array([\"T-shirt / Top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle Boot\"])\n",
    "\n",
    "#summarize the classes 0 and 6\n",
    "summarize_shirt = False\n",
    "if summarize_shirt == True:\n",
    "    label_test[label_test==6]=0\n",
    "    label_test[label_test>=7]-=1\n",
    "    label_train[label_train==6]=0\n",
    "    label_train[label_train>=7]-=1\n",
    "    cnn_label_test = tf.keras.utils.to_categorical(label_test)\n",
    "    cnn_label_train = tf.keras.utils.to_categorical(label_train)\n",
    "    softmax_nodes -= 1\n",
    "    class_names = np.delete(class_names,6)\n",
    "\n",
    "    shirts_pixel = traindata_pixel[(og_label_train==6)|(og_label_train==0)]\n",
    "    shirts_pixel = shirts_pixel.reshape(-1,28,28) /255.0\n",
    "    shirts_pixel = np.expand_dims(shirts_pixel,axis=3)\n",
    "    label_shirts = og_label_train[(og_label_train==6)|(og_label_train==0)]\n",
    "    label_shirts[label_shirts==6]=1\n",
    "    label_shirts = tf.keras.utils.to_categorical(label_shirts)\n",
    "\n",
    "    shirts_pixel_val = testdata_pixel[(og_label_test==6)|(og_label_test==0)]\n",
    "    shirts_pixel_val = shirts_pixel_val.reshape(-1,28,28) /255.0\n",
    "    shirts_pixel_val = np.expand_dims(shirts_pixel_val,axis=3)\n",
    "    label_shirts_val = og_label_test[(og_label_test==6)|(og_label_test==0)].copy()\n",
    "    label_shirts_val[label_shirts_val==6]=1\n",
    "    label_shirts_val = tf.keras.utils.to_categorical(label_shirts_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Plots/baschti.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[39mreturn\u001b[39;00m final_image\n\u001b[0;32m     21\u001b[0m your_image \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mPlots/baschti.jpg\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 22\u001b[0m your_image \u001b[39m=\u001b[39m convert_image_to_grayscale(your_image)\n\u001b[0;32m     23\u001b[0m plt\u001b[39m.\u001b[39mimshow(your_image,cmap\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgray\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m plt\u001b[39m.\u001b[39msavefig(\u001b[39m'\u001b[39m\u001b[39mPlots/baschti.svg\u001b[39m\u001b[39m'\u001b[39m,\u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msvg\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m, in \u001b[0;36mconvert_image_to_grayscale\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconvert_image_to_grayscale\u001b[39m(image_path):\n\u001b[0;32m      5\u001b[0m     \u001b[39m# Open the image\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m     image \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39;49mopen(image_path)\u001b[39m.\u001b[39mconvert(\u001b[39m'\u001b[39m\u001b[39mL\u001b[39m\u001b[39m'\u001b[39m)  \u001b[39m# Convert to grayscale\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[39m# Resize the image to 28x28 pixels\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     resized_image \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39mresize((\u001b[39m28\u001b[39m, \u001b[39m28\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Ole Decker\\mambaforge\\envs\\compmeth2022\\lib\\site-packages\\PIL\\Image.py:2953\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   2950\u001b[0m     filename \u001b[39m=\u001b[39m fp\n\u001b[0;32m   2952\u001b[0m \u001b[39mif\u001b[39;00m filename:\n\u001b[1;32m-> 2953\u001b[0m     fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39;49mopen(filename, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m   2954\u001b[0m     exclusive_fp \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   2956\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Plots/baschti.jpg'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def convert_image_to_grayscale(image_path):\n",
    "    # Open the image\n",
    "    image = Image.open(image_path).convert('L')  # Convert to grayscale\n",
    "\n",
    "    # Resize the image to 28x28 pixels\n",
    "    resized_image = image.resize((28, 28))\n",
    "\n",
    "    # Convert the image to a NumPy array\n",
    "    numpy_image = np.array(resized_image)\n",
    "\n",
    "    # Normalize intensity values between 0 and 255\n",
    "    normalized_image = (numpy_image / np.max(numpy_image)) * -255\n",
    "\n",
    "    # Convert intensity values to integers\n",
    "    final_image = normalized_image.astype(np.uint8)\n",
    "\n",
    "    return final_image\n",
    "your_image = \"Plots/baschti.jpg\"\n",
    "your_image = convert_image_to_grayscale(your_image)\n",
    "plt.imshow(your_image,cmap=\"gray\")\n",
    "plt.savefig('Plots/baschti.svg',format=\"svg\")\n",
    "your_image = your_image.reshape(-1,28,28) / 255.0\n",
    "your_image = np.expand_dims(your_image,axis=3)\n",
    "model = tf.keras.models.load_model('Results/model_shirts_notsum')\n",
    "for i,prob in enumerate(np.round(model.predict(your_image)[0],3)):\n",
    "    print(str(class_names[i])+\": \" + str(prob))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now loaded and reshaped the data. The labels were converted into 10-dimensional to be compatible with the output of the softmax activation function and the dimension of the images was increased by one to show that there is only one color channel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1110/1875 [================>.............] - ETA: 9s - loss: 0.5185 - accuracy: 0.8086"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 16\u001b[0m\n\u001b[0;32m      1\u001b[0m lenet5_model \u001b[39m=\u001b[39m Sequential([\n\u001b[0;32m      2\u001b[0m   Conv2D(\u001b[39m6\u001b[39m, \u001b[39m5\u001b[39m, input_shape\u001b[39m=\u001b[39m(\u001b[39m28\u001b[39m, \u001b[39m28\u001b[39m, \u001b[39m1\u001b[39m), activation\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m\"\u001b[39m,padding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msame\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m      3\u001b[0m   MaxPooling2D(pool_size\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,strides\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m   Dense(softmax_nodes, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[0;32m     10\u001b[0m ])\n\u001b[0;32m     11\u001b[0m lenet5_model\u001b[39m.\u001b[39mcompile(\n\u001b[0;32m     12\u001b[0m   \u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     13\u001b[0m   loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     14\u001b[0m   metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     15\u001b[0m )\n\u001b[1;32m---> 16\u001b[0m lenet5_model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m     17\u001b[0m   cnn_train,\n\u001b[0;32m     18\u001b[0m   cnn_label_train,\n\u001b[0;32m     19\u001b[0m   epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m,\n\u001b[0;32m     20\u001b[0m   validation_data\u001b[39m=\u001b[39;49m(cnn_test, cnn_label_test)\n\u001b[0;32m     21\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Ole Decker\\mambaforge\\envs\\compmeth2022\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Ole Decker\\mambaforge\\envs\\compmeth2022\\lib\\site-packages\\keras\\engine\\training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1678\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1679\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1683\u001b[0m ):\n\u001b[0;32m   1684\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1685\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1687\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Ole Decker\\mambaforge\\envs\\compmeth2022\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Ole Decker\\mambaforge\\envs\\compmeth2022\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Ole Decker\\mambaforge\\envs\\compmeth2022\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    923\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    924\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    925\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 926\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_no_variable_creation_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    929\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    930\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\Ole Decker\\mambaforge\\envs\\compmeth2022\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\Ole Decker\\mambaforge\\envs\\compmeth2022\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Ole Decker\\mambaforge\\envs\\compmeth2022\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\Ole Decker\\mambaforge\\envs\\compmeth2022\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lenet5_model = Sequential([\n",
    "  Conv2D(6, 5, input_shape=(28, 28, 1), activation=\"relu\",padding=\"same\"),\n",
    "  MaxPooling2D(pool_size=2,strides=2),\n",
    "  Conv2D(16, 5, activation=\"relu\",padding=\"valid\"),\n",
    "  MaxPooling2D(pool_size=2,strides=2),\n",
    "  Conv2D(120, 5, activation=\"relu\",padding=\"valid\"),\n",
    "  Flatten(),\n",
    "  Dense(84,activation=\"relu\"),\n",
    "  Dense(softmax_nodes, activation='softmax'),\n",
    "])\n",
    "lenet5_model.compile(\n",
    "  'adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")\n",
    "lenet5_model.fit(\n",
    "  cnn_train,\n",
    "  cnn_label_train,\n",
    "  epochs=20,\n",
    "  validation_data=(cnn_test, cnn_label_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3240 - accuracy: 0.9085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3240226209163666, 0.9085000157356262]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenet5_model.evaluate(cnn_test,cnn_label_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous code used a modifyed LeNet-5 architecture with max pooling instead of mean pooling and ReLU activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 82s 167ms/step - loss: 0.5797 - accuracy: 0.7845 - val_loss: 0.6758 - val_accuracy: 0.7476\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 137s 292ms/step - loss: 0.3626 - accuracy: 0.8670 - val_loss: 0.3314 - val_accuracy: 0.8734\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 147s 313ms/step - loss: 0.3150 - accuracy: 0.8846 - val_loss: 0.3066 - val_accuracy: 0.8848\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 121s 257ms/step - loss: 0.2808 - accuracy: 0.8974 - val_loss: 0.2882 - val_accuracy: 0.8911\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 131s 279ms/step - loss: 0.2594 - accuracy: 0.9050 - val_loss: 0.2667 - val_accuracy: 0.9003\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 152s 323ms/step - loss: 0.2501 - accuracy: 0.9094 - val_loss: 0.2991 - val_accuracy: 0.8926\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 152s 324ms/step - loss: 0.2353 - accuracy: 0.9140 - val_loss: 0.2592 - val_accuracy: 0.9061\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 140s 299ms/step - loss: 0.2220 - accuracy: 0.9192 - val_loss: 0.2476 - val_accuracy: 0.9114\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 154s 328ms/step - loss: 0.2161 - accuracy: 0.9202 - val_loss: 0.2586 - val_accuracy: 0.9056\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 135s 287ms/step - loss: 0.2044 - accuracy: 0.9252 - val_loss: 0.2493 - val_accuracy: 0.9123\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 170s 362ms/step - loss: 0.1991 - accuracy: 0.9268 - val_loss: 0.2509 - val_accuracy: 0.9113\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 147s 314ms/step - loss: 0.1899 - accuracy: 0.9301 - val_loss: 0.2276 - val_accuracy: 0.9162\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 162s 346ms/step - loss: 0.1846 - accuracy: 0.9316 - val_loss: 0.2313 - val_accuracy: 0.9170\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 137s 292ms/step - loss: 0.1770 - accuracy: 0.9350 - val_loss: 0.2528 - val_accuracy: 0.9089\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 153s 327ms/step - loss: 0.1729 - accuracy: 0.9350 - val_loss: 0.2426 - val_accuracy: 0.9140\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 141s 300ms/step - loss: 0.1654 - accuracy: 0.9399 - val_loss: 0.2483 - val_accuracy: 0.9078\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 125s 267ms/step - loss: 0.1586 - accuracy: 0.9420 - val_loss: 0.2491 - val_accuracy: 0.9155\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 124s 265ms/step - loss: 0.1595 - accuracy: 0.9403 - val_loss: 0.2328 - val_accuracy: 0.9194\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 126s 269ms/step - loss: 0.1517 - accuracy: 0.9439 - val_loss: 0.2399 - val_accuracy: 0.9184\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 125s 267ms/step - loss: 0.1489 - accuracy: 0.9454 - val_loss: 0.2274 - val_accuracy: 0.9221\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b2dc3c1c30>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_model = Sequential([\n",
    "  Conv2D(32, 3, input_shape=(28, 28, 1), activation=\"relu\",padding=\"same\"),\n",
    "  Conv2D(32, 3, activation=\"relu\",padding=\"same\"),\n",
    "  MaxPooling2D(pool_size=2,strides=2),\n",
    "  BatchNormalization(),\n",
    "  Conv2D(16, 3, activation=\"relu\",padding=\"same\"),\n",
    "  Conv2D(16, 3, activation=\"relu\",padding=\"same\"),\n",
    "  MaxPooling2D(pool_size=2,strides=2),\n",
    "  BatchNormalization(),\n",
    "  Conv2D(16, 3, activation=\"relu\",padding=\"same\"),\n",
    "  Conv2D(16, 3, activation=\"relu\",padding=\"same\"),\n",
    "  MaxPooling2D(pool_size=2,strides=2),\n",
    "  BatchNormalization(),\n",
    "  Conv2D(16, 3, activation=\"relu\",padding=\"same\"),\n",
    "  Conv2D(16, 3, activation=\"relu\",padding=\"same\"),\n",
    "  MaxPooling2D(pool_size=2,strides=1),\n",
    "  BatchNormalization(),\n",
    "  Conv2D(16, 3, activation=\"relu\",padding=\"same\"),\n",
    "  Conv2D(16, 3, activation=\"relu\",padding=\"same\"),\n",
    "  MaxPooling2D(pool_size=2,strides=1),\n",
    "  BatchNormalization(),\n",
    "  Flatten(),\n",
    "  Dense(256,activation=\"relu\"),\n",
    "  Dropout(0.15),\n",
    "  Dense(256,activation=\"relu\"),\n",
    "  Dropout(0.15),\n",
    "  Dense(softmax_nodes, activation='softmax'),\n",
    "])\n",
    "vgg_model.compile(\n",
    "  'adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")\n",
    "vgg_model.fit(\n",
    "  cnn_train,\n",
    "  cnn_label_train,\n",
    "  epochs=20,\n",
    "  validation_data=(cnn_test, cnn_label_test),\n",
    "  batch_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "235/235 [==============================] - 154s 631ms/step - loss: 0.3968 - accuracy: 0.8572 - val_loss: 2.1812 - val_accuracy: 0.3373\n",
      "Epoch 2/5\n",
      "235/235 [==============================] - 139s 591ms/step - loss: 0.2423 - accuracy: 0.9136 - val_loss: 0.3707 - val_accuracy: 0.8673\n",
      "Epoch 3/5\n",
      "235/235 [==============================] - 97s 414ms/step - loss: 0.2033 - accuracy: 0.9269 - val_loss: 0.2050 - val_accuracy: 0.9276\n",
      "Epoch 4/5\n",
      "235/235 [==============================] - 95s 405ms/step - loss: 0.1773 - accuracy: 0.9373 - val_loss: 0.2201 - val_accuracy: 0.9267\n",
      "Epoch 5/5\n",
      "235/235 [==============================] - 130s 555ms/step - loss: 0.1605 - accuracy: 0.9422 - val_loss: 0.2185 - val_accuracy: 0.9269\n"
     ]
    }
   ],
   "source": [
    "complex_model = Sequential([\n",
    "  Conv2D(16, 5, input_shape=(28, 28, 1), activation=\"relu\",padding=\"same\"),\n",
    "  Conv2D(16, 5, activation=\"relu\",padding=\"same\"),\n",
    "  MaxPooling2D(pool_size=2,strides=2),\n",
    "  BatchNormalization(),\n",
    "  Conv2D(32, 3, activation=\"relu\",padding=\"same\"),\n",
    "  Conv2D(32, 3, activation=\"relu\",padding=\"same\"),\n",
    "  MaxPooling2D(pool_size=2,strides=2),\n",
    "  BatchNormalization(),\n",
    "  Conv2D(64, 3, activation=\"relu\",padding=\"same\"),\n",
    "  Conv2D(64, 3, activation=\"relu\",padding=\"same\"),\n",
    "  MaxPooling2D(pool_size=2,strides=2),\n",
    "  BatchNormalization(),\n",
    "  Conv2D(64, 3, activation=\"relu\",padding=\"same\"),\n",
    "  Conv2D(64, 3, activation=\"relu\",padding=\"same\"),\n",
    "  Conv2D(64, 3, activation=\"relu\",padding=\"same\"),\n",
    "  MaxPooling2D(pool_size=2,strides=1),\n",
    "  BatchNormalization(),\n",
    "  Flatten(),\n",
    "  Dense(256,activation=\"relu\"),\n",
    "  Dropout(0.1),\n",
    "  Dense(512,activation=\"relu\"),\n",
    "  Dropout(0.1),\n",
    "  Dense(softmax_nodes, activation='softmax'),\n",
    "])\n",
    "complex_model.compile(\n",
    "  'adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")\n",
    "tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='loss',\n",
    "    min_delta=0.01,\n",
    "    patience=2,\n",
    "    verbose=0,\n",
    "    mode='auto',\n",
    "    restore_best_weights=True,\n",
    "    start_from_epoch=0\n",
    ")\n",
    "history = complex_model.fit(\n",
    "  cnn_train,\n",
    "  cnn_label_train,\n",
    "  epochs = 5,\n",
    "  validation_data=(cnn_test, cnn_label_test),\n",
    "  batch_size=256\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Results/deep_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Results/deep_model\\assets\n"
     ]
    }
   ],
   "source": [
    "complex_model.save('Results/deep_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 11ms/step\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 9 is out of bounds for axis 1 with size 9",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m):\n\u001b[0;32m     11\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39m!=\u001b[39m j:\n\u001b[1;32m---> 12\u001b[0m         conf_df\u001b[39m.\u001b[39mvalues[i,j] \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m1\u001b[39m\u001b[39m-\u001b[39macc)\u001b[39m*\u001b[39mrowsums[i]\u001b[39m/\u001b[39m\u001b[39m9\u001b[39m\n\u001b[0;32m     13\u001b[0m         conf_df\u001b[39m.\u001b[39mvalues[i,j] \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m     14\u001b[0m     \u001b[39melse\u001b[39;00m: \n",
      "\u001b[1;31mIndexError\u001b[0m: index 9 is out of bounds for axis 1 with size 9"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('Results/complex_model')\n",
    "y_pred = model.predict(cnn_test)\n",
    "y_pred = np.argmax(y_pred,axis=1)\n",
    "conf = sklearn.metrics.confusion_matrix(y_pred, label_test)\n",
    "conf_df = pnd.DataFrame(conf, index=class_names, columns=class_names)\n",
    "rowsums = conf_df.sum(axis=1)\n",
    "acc = np.sum(y_pred == label_test)/ len(label_test)\n",
    "\n",
    "# for i in range(10):\n",
    "#     for j in range(10):\n",
    "#         if i != j:\n",
    "#             conf_df.values[i,j] -= (1-acc)*rowsums[i]/9\n",
    "#             conf_df.values[i,j] *= -1\n",
    "#         else: \n",
    "#             conf_df.values[i,j] -= acc*rowsums[i]\n",
    "# sns.heatmap(conf_df, annot=True, cmap= \"RdBu\", annot_kws={\"fontsize\":6},fmt=\",.1f\",center=0,vmax=250,vmin=-250)\n",
    "# #plt.savefig('cnn_chi.png',dpi=600)\n",
    "# import visualkeras \n",
    "# visualkeras.layered_view(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "47/47 [==============================] - 6s 85ms/step - loss: 0.4683 - accuracy: 0.7942 - val_loss: 0.4009 - val_accuracy: 0.8045\n",
      "Epoch 2/75\n",
      "47/47 [==============================] - 3s 72ms/step - loss: 0.3588 - accuracy: 0.8357 - val_loss: 0.3644 - val_accuracy: 0.8370\n",
      "Epoch 3/75\n",
      "47/47 [==============================] - 3s 74ms/step - loss: 0.3381 - accuracy: 0.8487 - val_loss: 0.3603 - val_accuracy: 0.8390\n",
      "Epoch 4/75\n",
      "47/47 [==============================] - 3s 69ms/step - loss: 0.3282 - accuracy: 0.8525 - val_loss: 0.3387 - val_accuracy: 0.8490\n",
      "Epoch 5/75\n",
      "47/47 [==============================] - 3s 68ms/step - loss: 0.3083 - accuracy: 0.8628 - val_loss: 0.3423 - val_accuracy: 0.8325\n",
      "Epoch 6/75\n",
      "47/47 [==============================] - 3s 67ms/step - loss: 0.3072 - accuracy: 0.8626 - val_loss: 0.3230 - val_accuracy: 0.8520\n",
      "Epoch 7/75\n",
      "47/47 [==============================] - 3s 69ms/step - loss: 0.2857 - accuracy: 0.8713 - val_loss: 0.3213 - val_accuracy: 0.8520\n",
      "Epoch 8/75\n",
      "47/47 [==============================] - 3s 72ms/step - loss: 0.2731 - accuracy: 0.8801 - val_loss: 0.3028 - val_accuracy: 0.8675\n",
      "Epoch 9/75\n",
      "47/47 [==============================] - 3s 73ms/step - loss: 0.2659 - accuracy: 0.8825 - val_loss: 0.2989 - val_accuracy: 0.8670\n",
      "Epoch 10/75\n",
      "47/47 [==============================] - 3s 70ms/step - loss: 0.2612 - accuracy: 0.8831 - val_loss: 0.3018 - val_accuracy: 0.8590\n",
      "Epoch 11/75\n",
      "47/47 [==============================] - 3s 69ms/step - loss: 0.2519 - accuracy: 0.8885 - val_loss: 0.2875 - val_accuracy: 0.8670\n",
      "Epoch 12/75\n",
      "47/47 [==============================] - 3s 69ms/step - loss: 0.2397 - accuracy: 0.8940 - val_loss: 0.2913 - val_accuracy: 0.8645\n",
      "Epoch 13/75\n",
      "47/47 [==============================] - 3s 71ms/step - loss: 0.2316 - accuracy: 0.8976 - val_loss: 0.2914 - val_accuracy: 0.8690\n",
      "Epoch 14/75\n",
      "47/47 [==============================] - 4s 78ms/step - loss: 0.2318 - accuracy: 0.8958 - val_loss: 0.2969 - val_accuracy: 0.8615\n",
      "Epoch 15/75\n",
      "47/47 [==============================] - 4s 80ms/step - loss: 0.2225 - accuracy: 0.9011 - val_loss: 0.2873 - val_accuracy: 0.8700\n",
      "Epoch 16/75\n",
      "47/47 [==============================] - 4s 78ms/step - loss: 0.2219 - accuracy: 0.9026 - val_loss: 0.3062 - val_accuracy: 0.8625\n",
      "Epoch 17/75\n",
      "47/47 [==============================] - 3s 74ms/step - loss: 0.2078 - accuracy: 0.9089 - val_loss: 0.2878 - val_accuracy: 0.8715\n",
      "Epoch 18/75\n",
      "47/47 [==============================] - 3s 73ms/step - loss: 0.1997 - accuracy: 0.9153 - val_loss: 0.2867 - val_accuracy: 0.8715\n",
      "Epoch 19/75\n",
      "47/47 [==============================] - 3s 70ms/step - loss: 0.2005 - accuracy: 0.9140 - val_loss: 0.2856 - val_accuracy: 0.8735\n",
      "Epoch 20/75\n",
      "47/47 [==============================] - 3s 72ms/step - loss: 0.1919 - accuracy: 0.9177 - val_loss: 0.2881 - val_accuracy: 0.8760\n",
      "Epoch 21/75\n",
      "47/47 [==============================] - 3s 72ms/step - loss: 0.1860 - accuracy: 0.9207 - val_loss: 0.2902 - val_accuracy: 0.8775\n",
      "Epoch 22/75\n",
      "47/47 [==============================] - 3s 73ms/step - loss: 0.1782 - accuracy: 0.9236 - val_loss: 0.2992 - val_accuracy: 0.8750\n",
      "Epoch 23/75\n",
      "47/47 [==============================] - 3s 72ms/step - loss: 0.1792 - accuracy: 0.9227 - val_loss: 0.2874 - val_accuracy: 0.8695\n",
      "Epoch 24/75\n",
      "47/47 [==============================] - 3s 71ms/step - loss: 0.1690 - accuracy: 0.9300 - val_loss: 0.2909 - val_accuracy: 0.8795\n",
      "Epoch 25/75\n",
      "47/47 [==============================] - 4s 78ms/step - loss: 0.1654 - accuracy: 0.9292 - val_loss: 0.3087 - val_accuracy: 0.8700\n",
      "Epoch 26/75\n",
      "47/47 [==============================] - 4s 92ms/step - loss: 0.1626 - accuracy: 0.9325 - val_loss: 0.2996 - val_accuracy: 0.8685\n",
      "Epoch 27/75\n",
      "47/47 [==============================] - 6s 132ms/step - loss: 0.1600 - accuracy: 0.9338 - val_loss: 0.2924 - val_accuracy: 0.8705\n",
      "Epoch 28/75\n",
      "47/47 [==============================] - 5s 101ms/step - loss: 0.1693 - accuracy: 0.9253 - val_loss: 0.3096 - val_accuracy: 0.8660\n",
      "Epoch 29/75\n",
      "47/47 [==============================] - 4s 75ms/step - loss: 0.1445 - accuracy: 0.9408 - val_loss: 0.3073 - val_accuracy: 0.8700\n",
      "Epoch 30/75\n",
      "47/47 [==============================] - 4s 89ms/step - loss: 0.1563 - accuracy: 0.9305 - val_loss: 0.3044 - val_accuracy: 0.8740\n",
      "Epoch 31/75\n",
      "47/47 [==============================] - 5s 112ms/step - loss: 0.1420 - accuracy: 0.9403 - val_loss: 0.3088 - val_accuracy: 0.8720\n",
      "Epoch 32/75\n",
      "47/47 [==============================] - 7s 140ms/step - loss: 0.1365 - accuracy: 0.9427 - val_loss: 0.3150 - val_accuracy: 0.8720\n",
      "Epoch 33/75\n",
      "47/47 [==============================] - 6s 123ms/step - loss: 0.1308 - accuracy: 0.9464 - val_loss: 0.3392 - val_accuracy: 0.8690\n",
      "Epoch 34/75\n",
      "47/47 [==============================] - 4s 95ms/step - loss: 0.1292 - accuracy: 0.9457 - val_loss: 0.3173 - val_accuracy: 0.8770\n",
      "Epoch 35/75\n",
      "47/47 [==============================] - 5s 96ms/step - loss: 0.1217 - accuracy: 0.9502 - val_loss: 0.3207 - val_accuracy: 0.8750\n",
      "Epoch 36/75\n",
      "47/47 [==============================] - 4s 89ms/step - loss: 0.1169 - accuracy: 0.9524 - val_loss: 0.3205 - val_accuracy: 0.8785\n",
      "Epoch 37/75\n",
      "47/47 [==============================] - 4s 94ms/step - loss: 0.1104 - accuracy: 0.9557 - val_loss: 0.3513 - val_accuracy: 0.8755\n",
      "Epoch 38/75\n",
      "47/47 [==============================] - 7s 142ms/step - loss: 0.1072 - accuracy: 0.9565 - val_loss: 0.3268 - val_accuracy: 0.8760\n",
      "Epoch 39/75\n",
      "47/47 [==============================] - 6s 135ms/step - loss: 0.0998 - accuracy: 0.9597 - val_loss: 0.3608 - val_accuracy: 0.8725\n",
      "Epoch 40/75\n",
      "47/47 [==============================] - 5s 104ms/step - loss: 0.0996 - accuracy: 0.9607 - val_loss: 0.3604 - val_accuracy: 0.8750\n",
      "Epoch 41/75\n",
      "47/47 [==============================] - 4s 94ms/step - loss: 0.0994 - accuracy: 0.9608 - val_loss: 0.3882 - val_accuracy: 0.8705\n",
      "Epoch 42/75\n",
      "47/47 [==============================] - 4s 91ms/step - loss: 0.0960 - accuracy: 0.9612 - val_loss: 0.3953 - val_accuracy: 0.8710\n",
      "Epoch 43/75\n",
      "47/47 [==============================] - 4s 82ms/step - loss: 0.0985 - accuracy: 0.9606 - val_loss: 0.3654 - val_accuracy: 0.8790\n",
      "Epoch 44/75\n",
      "47/47 [==============================] - 4s 84ms/step - loss: 0.0889 - accuracy: 0.9635 - val_loss: 0.3870 - val_accuracy: 0.8725\n",
      "Epoch 45/75\n",
      "47/47 [==============================] - 5s 99ms/step - loss: 0.0817 - accuracy: 0.9686 - val_loss: 0.3739 - val_accuracy: 0.8805\n",
      "Epoch 46/75\n",
      "47/47 [==============================] - 5s 108ms/step - loss: 0.0740 - accuracy: 0.9728 - val_loss: 0.3884 - val_accuracy: 0.8735\n",
      "Epoch 47/75\n",
      "47/47 [==============================] - 5s 103ms/step - loss: 0.0770 - accuracy: 0.9691 - val_loss: 0.3841 - val_accuracy: 0.8780\n",
      "Epoch 48/75\n",
      "47/47 [==============================] - 6s 119ms/step - loss: 0.0797 - accuracy: 0.9690 - val_loss: 0.4151 - val_accuracy: 0.8715\n",
      "Epoch 49/75\n",
      "47/47 [==============================] - 5s 110ms/step - loss: 0.0813 - accuracy: 0.9662 - val_loss: 0.4171 - val_accuracy: 0.8800\n",
      "Epoch 50/75\n",
      "47/47 [==============================] - 5s 106ms/step - loss: 0.0809 - accuracy: 0.9674 - val_loss: 0.4086 - val_accuracy: 0.8790\n",
      "Epoch 51/75\n",
      "47/47 [==============================] - 4s 94ms/step - loss: 0.0674 - accuracy: 0.9752 - val_loss: 0.4300 - val_accuracy: 0.8800\n",
      "Epoch 52/75\n",
      "47/47 [==============================] - 4s 83ms/step - loss: 0.0577 - accuracy: 0.9788 - val_loss: 0.4759 - val_accuracy: 0.8735\n",
      "Epoch 53/75\n",
      "47/47 [==============================] - 4s 80ms/step - loss: 0.0643 - accuracy: 0.9754 - val_loss: 0.4354 - val_accuracy: 0.8850\n",
      "Epoch 54/75\n",
      "47/47 [==============================] - 4s 83ms/step - loss: 0.0539 - accuracy: 0.9794 - val_loss: 0.4619 - val_accuracy: 0.8840\n",
      "Epoch 55/75\n",
      "47/47 [==============================] - 4s 88ms/step - loss: 0.0577 - accuracy: 0.9780 - val_loss: 0.4577 - val_accuracy: 0.8835\n",
      "Epoch 56/75\n",
      "47/47 [==============================] - 5s 110ms/step - loss: 0.0541 - accuracy: 0.9800 - val_loss: 0.4858 - val_accuracy: 0.8785\n",
      "Epoch 57/75\n",
      "47/47 [==============================] - 6s 131ms/step - loss: 0.0444 - accuracy: 0.9844 - val_loss: 0.4963 - val_accuracy: 0.8795\n",
      "Epoch 58/75\n",
      "47/47 [==============================] - 6s 120ms/step - loss: 0.0535 - accuracy: 0.9789 - val_loss: 0.4869 - val_accuracy: 0.8815\n",
      "Epoch 59/75\n",
      "47/47 [==============================] - 4s 83ms/step - loss: 0.0514 - accuracy: 0.9804 - val_loss: 0.5207 - val_accuracy: 0.8830\n",
      "Epoch 60/75\n",
      "47/47 [==============================] - 4s 87ms/step - loss: 0.0393 - accuracy: 0.9872 - val_loss: 0.5335 - val_accuracy: 0.8765\n",
      "Epoch 61/75\n",
      "47/47 [==============================] - 4s 87ms/step - loss: 0.0470 - accuracy: 0.9822 - val_loss: 0.5379 - val_accuracy: 0.8815\n",
      "Epoch 62/75\n",
      "47/47 [==============================] - 4s 86ms/step - loss: 0.0610 - accuracy: 0.9755 - val_loss: 0.5303 - val_accuracy: 0.8810\n",
      "Epoch 63/75\n",
      "47/47 [==============================] - 4s 83ms/step - loss: 0.0415 - accuracy: 0.9841 - val_loss: 0.5268 - val_accuracy: 0.8815\n",
      "Epoch 64/75\n",
      "47/47 [==============================] - 4s 84ms/step - loss: 0.0358 - accuracy: 0.9866 - val_loss: 0.5573 - val_accuracy: 0.8850\n",
      "Epoch 65/75\n",
      "47/47 [==============================] - 4s 87ms/step - loss: 0.0471 - accuracy: 0.9827 - val_loss: 0.5593 - val_accuracy: 0.8785\n",
      "Epoch 66/75\n",
      "47/47 [==============================] - 4s 91ms/step - loss: 0.0333 - accuracy: 0.9882 - val_loss: 0.5884 - val_accuracy: 0.8790\n",
      "Epoch 67/75\n",
      "47/47 [==============================] - 4s 91ms/step - loss: 0.0279 - accuracy: 0.9902 - val_loss: 0.5669 - val_accuracy: 0.8830\n",
      "Epoch 68/75\n",
      "47/47 [==============================] - 4s 85ms/step - loss: 0.0250 - accuracy: 0.9918 - val_loss: 0.6261 - val_accuracy: 0.8820\n",
      "Epoch 69/75\n",
      "47/47 [==============================] - 4s 88ms/step - loss: 0.0311 - accuracy: 0.9893 - val_loss: 0.5794 - val_accuracy: 0.8815\n",
      "Epoch 70/75\n",
      "47/47 [==============================] - 4s 87ms/step - loss: 0.0199 - accuracy: 0.9939 - val_loss: 0.6527 - val_accuracy: 0.8855\n",
      "Epoch 71/75\n",
      "47/47 [==============================] - 4s 86ms/step - loss: 0.0194 - accuracy: 0.9941 - val_loss: 0.6429 - val_accuracy: 0.8790\n",
      "Epoch 72/75\n",
      "47/47 [==============================] - 4s 85ms/step - loss: 0.0177 - accuracy: 0.9950 - val_loss: 0.6919 - val_accuracy: 0.8770\n",
      "Epoch 73/75\n",
      "47/47 [==============================] - 4s 88ms/step - loss: 0.0239 - accuracy: 0.9920 - val_loss: 0.6714 - val_accuracy: 0.8820\n",
      "Epoch 74/75\n",
      "47/47 [==============================] - 4s 89ms/step - loss: 0.0449 - accuracy: 0.9828 - val_loss: 0.6472 - val_accuracy: 0.8840\n",
      "Epoch 75/75\n",
      "47/47 [==============================] - 4s 85ms/step - loss: 0.0264 - accuracy: 0.9902 - val_loss: 0.6948 - val_accuracy: 0.8740\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2170375b220>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenet5_shirt_model = Sequential([\n",
    "  Conv2D(6, 5, input_shape=(28, 28, 1), activation=\"relu\",padding=\"same\"),\n",
    "  MaxPooling2D(pool_size=2,strides=2),\n",
    "  Conv2D(16, 5, activation=\"relu\",padding=\"valid\"),\n",
    "  MaxPooling2D(pool_size=2,strides=2),\n",
    "  Conv2D(120, 5, activation=\"relu\",padding=\"valid\"),\n",
    "  Flatten(),\n",
    "  Dense(84,activation=\"relu\"),\n",
    "  Dense(2, activation='softmax'),\n",
    "])\n",
    "lenet5_shirt_model.compile(\n",
    "  'adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")\n",
    "lenet5_shirt_model.fit(\n",
    "  shirts_pixel,\n",
    "  label_shirts,\n",
    "  epochs=75,\n",
    "  validation_data = (shirts_pixel_val,label_shirts_val),\n",
    "  batch_size = 256\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'complex_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m predictions \u001b[39m=\u001b[39m complex_model\u001b[39m.\u001b[39mpredict(cnn_test)\n\u001b[0;32m      2\u001b[0m predictions \u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39margmax(predictions, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      3\u001b[0m predictions[predictions\u001b[39m>\u001b[39m\u001b[39m=\u001b[39m\u001b[39m6\u001b[39m]\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'complex_model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "predictions = complex_model.predict(cnn_test)\n",
    "predictions =np.argmax(predictions, axis=1)\n",
    "predictions[predictions>=6]+=1\n",
    "prediction_shirt = cnn_test[predictions==0]\n",
    "prediction_shirt_final = lenet5_shirt_model.predict(prediction_shirt)\n",
    "prediction_shirt_final = np.argmax(prediction_shirt_final,axis=1) \n",
    "index = np.where(predictions==0)[0]\n",
    "for i in range(np.sum(predictions==0)):\n",
    "    if prediction_shirt_final[i]==1:\n",
    "        predictions[index[i]] = 6\n",
    "print(np.sum(predictions==og_label_test)/len(og_label_test))\n",
    "print(np.sum(predictions==6))\n",
    "y_pred = predictions\n",
    "y_true = og_label_test #label seems to be wrong\n",
    "class_names = np.array([\"T-shirt / Top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle Boot\"])\n",
    "conf = confusion_matrix(y_pred, y_true)\n",
    "conf_df = pnd.DataFrame(conf, index=class_names, columns=class_names)\n",
    "print(conf_df)\n",
    "sns.heatmap(conf_df, annot=True, cmap='RdYlGn')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compmeth2022",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
